import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
from PIL import Image
import shap
from lime import lime_tabular
import matplotlib.pyplot as plt
import plotly.express as px
import warnings
import pickle
from datetime import datetime
import streamlit.components.v1 as components
import io

# --- ä¸­æ–‡å­—ä½“é…ç½® ---
# è§£å†³Matplotlibä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
try:
    plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
except Exception:
    plt.rcParams['font.sans-serif'] = ['sans-serif'] # å›é€€åˆ°é€šç”¨æ— è¡¬çº¿å­—ä½“
    plt.rcParams['axes.unicode_minus'] = False
    st.warning("ä¸­æ–‡å­—ä½“ 'SimHei' æœªæ‰¾åˆ°ï¼Œå›¾è¡¨å°†ä½¿ç”¨é»˜è®¤è‹±æ–‡å­—ä½“æ˜¾ç¤ºã€‚")

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title='ICUè‚¾è„æ›¿ä»£æ²»ç–—ä½è¡€å‹é£é™©é¢„æµ‹',
    page_icon='ğŸ’‰',
    layout='wide'
)

# --- èµ„æºåŠ è½½ (ä½¿ç”¨ç¼“å­˜) ---
@st.cache_resource
def load_model(model_path):
    """åŠ è½½XGBoost .jsonæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶"""
    model = xgb.XGBClassifier()
    model.load_model(model_path)
    return model

@st.cache_resource
def load_feature_names(feature_path):
    """åŠ è½½æ¨¡å‹ç‰¹å¾åˆ—è¡¨"""
    with open(feature_path, 'rb') as f:
        features = pickle.load(f)
    return features

@st.cache_resource
def load_images(image_path):
    """åŠ è½½å›¾ç‰‡"""
    return Image.open(image_path)

@st.cache_data
def load_training_data(data_path="train.csv"):
    """åŠ è½½å¹¶ç¼“å­˜åŸå§‹è®­ç»ƒæ•°æ®"""
    data = pd.read_csv(data_path)
    if 'Unnamed: 0' in data.columns:
        data = data.drop('Unnamed: 0', axis=1)
    return data

def preprocess_data(data, feature_names):
    """å¯¹æ•°æ®è¿›è¡Œä¸è®­ç»ƒæ—¶ä¸€è‡´çš„é¢„å¤„ç†ï¼Œç”¨äºè§£é‡Šå™¨èƒŒæ™¯æ•°æ®é›†"""
    # è½¬æ¢ 'æ˜¯'/'å¦'
    binary_map = {'æ˜¯': 1, 'å¦': 0}
    for col in ['congestive_heart_failure', 'peripheral_vascular_disease', 'dementia', 
                'chronic_pulmonary_disease', 'mild_liver_disease', 'diabetes_without_cc', 
                'malignant_cancer', 'metastatic_solid_tumor', 'vasoactive_drugs']:
        if col in data.columns:
            # è®­ç»ƒæ•°æ®å·²ç»æ˜¯0/1ï¼Œæ­¤æ­¥ä¸»è¦ç”¨äºå¤„ç†sidebarä¸­æ¥çš„åŸå§‹æ•°æ®
            if data[col].dtype == 'object':
                 data[col] = data[col].map(binary_map)

    # å¯¹åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç 
    categorical_cols = ['gender', 'rrt_type']
    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)
    
    # ä½¿ç”¨ reindex ä¿è¯ç‰¹å¾åˆ—å®Œå…¨å¯¹é½
    X = data.reindex(columns=feature_names, fill_value=0)
    return X

# --- æ—¶é—´å·®è®¡ç®—å‡½æ•° ---
def calculate_hours_diff(start_date, start_time, end_date, end_time):
    """è®¡ç®—ä¸¤ä¸ªæ—¥æœŸæ—¶é—´ä¹‹é—´çš„å°æ—¶å·®"""
    start_dt = datetime.combine(start_date, start_time)
    end_dt = datetime.combine(end_date, end_time)
    diff = end_dt - start_dt
    return diff.total_seconds() / 3600

# --- UI ç»„ä»¶ ---
def sidebar_input_features(feature_names):
    """åœ¨ä¾§è¾¹æ ä¸­åˆ›å»ºç”¨æˆ·è¾“å…¥ç»„ä»¶"""
    st.sidebar.header('è¯·åœ¨ä¸‹æ–¹è¾“å…¥ç›¸å…³æŒ‡æ ‡â¬‡ï¸')
    
    # åˆå§‹åŒ–ç”¨æˆ·è¾“å…¥å­—å…¸
    user_inputs = {}
    
    # æ—¶é—´è¾“å…¥ç»„ä»¶
    st.sidebar.subheader("æ—¶é—´è®¡ç®—")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        st.markdown("**å…¥ä½ICUæ—¶é—´**")
        icu_date = st.date_input("æ—¥æœŸ", key="icu_date")
        icu_time = st.time_input("æ—¶é—´", key="icu_time")
    
    with col2:
        st.markdown("**è‚¾è„æ›¿ä»£æ²»ç–—å¼€å§‹æ—¶é—´**")
        rrt_date = st.date_input("æ—¥æœŸ", key="rrt_date")
        rrt_time = st.time_input("æ—¶é—´", key="rrt_time")
    
    # è®¡ç®—æ—¶é—´å·®
    icu_to_rrt_hours = calculate_hours_diff(icu_date, icu_time, rrt_date, rrt_time)
    st.sidebar.info(f"å…¥ä½ICUåˆ°è‚¾è„æ›¿ä»£æ²»ç–—å¼€å§‹æ—¶é—´å·®: **{icu_to_rrt_hours:.2f}å°æ—¶**")
    
    # ç‰¹å¾è¾“å…¥ç»„ä»¶
    st.sidebar.subheader("æ‚£è€…ç‰¹å¾")
    
    # å®šä¹‰æ¯ä¸ªç‰¹å¾çš„è¾“å…¥å‚æ•°
    input_params = [
        ('gender', 'æ€§åˆ«', 'selectbox', ('ç”·', 'å¥³'), None, None, None),
        ('admission_age', 'å¹´é¾„(å²)', 'slider', 18, 100, 60, 1),
        ('congestive_heart_failure', 'åˆå¹¶å……è¡€æ€§å¿ƒåŠ›è¡°ç«­', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('peripheral_vascular_disease', 'åˆå¹¶å¤–å‘¨è¡€ç®¡ç–¾ç—…', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('dementia', 'åˆå¹¶ç—´å‘†', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('chronic_pulmonary_disease', 'åˆå¹¶æ…¢æ€§è‚ºç—…', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('mild_liver_disease', 'åˆå¹¶è½»åº¦è‚ç—…', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('diabetes_without_cc', 'åˆå¹¶ç³–å°¿ç—…', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('malignant_cancer', 'æ‚£æœ‰æ¶æ€§è‚¿ç˜¤', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('metastatic_solid_tumor', 'è½¬ç§»æ€§å®ä½“ç˜¤', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('vasoactive_drugs', 'ä½¿ç”¨è¡€ç®¡æ´»æ€§è¯ç‰©', 'selectbox', ('æ˜¯', 'å¦'), None, None, None),
        ('ph', 'æœ€è¿‘ä¸€æ¬¡PHå€¼', 'slider', 7.00, 8.00, 7.40, 0.01),
        ('lactate', 'æœ€è¿‘ä¸€æ¬¡ä¹³é…¸å€¼(mmol/L)', 'slider', 0.0, 10.0, 2.0, 0.1),
        ('rrt_type', 'è‚¾è„æ›¿ä»£æ²»ç–—æ–¹å¼', 'selectbox', ('CRRT', 'IHD'), None, None, None),
        ('map', 'æ²»ç–—å‰å¹³å‡åŠ¨è„‰å‹(mmHg)', 'slider', 0, 250, 80, 1),
        ('sap', 'æ²»ç–—å‰æ”¶ç¼©å‹(mmHg)', 'slider', 0, 250, 120, 1),
    ]
    
    # åˆ›å»ºè¾“å…¥ç»„ä»¶
    for name, display, type, options, min_val, max_val, step in input_params:
        if type == 'slider':
            user_inputs[name] = st.sidebar.slider(display, min_value=min_val, max_value=max_val, value=options, step=step)
        elif type == 'selectbox':
            user_inputs[name] = st.sidebar.selectbox(display, options)
    
    # æ·»åŠ è®¡ç®—çš„æ—¶é—´å·®
    user_inputs['icu_to_rrt_hours'] = icu_to_rrt_hours
    
    # å°†ç”¨æˆ·è¾“å…¥æ„é€ æˆDataFrame
    input_df = pd.DataFrame([user_inputs])

    # ä½¿ç”¨ä¸è®­ç»ƒæ•°æ®ç›¸åŒçš„é¢„å¤„ç†æµç¨‹
    output_df = preprocess_data(input_df, feature_names)

    return output_df

def display_global_explanations(model, X_train, shap_image):
    """æ˜¾ç¤ºå…¨å±€æ¨¡å‹è§£é‡Šï¼ˆSHAPç‰¹å¾é‡è¦æ€§å›¾å’Œä¾èµ–å›¾ï¼‰"""
    st.subheader("SHAPå…¨å±€è§£é‡Š")

    # --- è®¡ç®—SHAPå€¼ ---
    with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼ï¼Œè¯·ç¨å€™..."):
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X_train)
    
    # å°†SHAPå€¼å’ŒåŸå§‹æ•°æ®è½¬æ¢ä¸ºDataFrame
    shap_value_df = pd.DataFrame(shap_values, columns=X_train.columns)
    shap_data_df = X_train

    f1, f2 = st.columns(2)

    with f1:
        st.write('**SHAPç‰¹å¾é‡è¦æ€§**')
        if shap_image:
            st.image(shap_image, use_container_width=True)
        else:
            st.warning("SHAPç‰¹å¾é‡è¦æ€§å›¾ ('shap.png') æœªæ‰¾åˆ°ã€‚è¯·å…ˆè¿è¡Œ `generate_shap_image.py` è„šæœ¬ã€‚")
        st.info('SHAPç‰¹å¾é‡è¦æ€§å›¾æ˜¾ç¤ºäº†å„ä¸ªç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„å¹³å‡å½±å“å¤§å°ã€‚å®ƒæ˜¯é€šè¿‡è®¡ç®—æ•°æ®é›†ä¸­æ¯ä¸ªç‰¹å¾çš„SHAPå€¼çš„å¹³å‡ç»å¯¹å€¼æ¥æ’åºçš„ã€‚æ¡å½¢è¶Šé•¿ï¼Œä»£è¡¨è¯¥ç‰¹å¾å¯¹æ¨¡å‹æ•´ä½“é¢„æµ‹ç»“æœçš„å½±å“è¶Šå¤§ã€‚')

    with f2:
        st.write('**SHAPä¾èµ–å›¾**')
        
        # æ¸…ç†ç‰¹å¾åä»¥ä¾¿æ˜¾ç¤º
        feature_options = [name.replace('_', ' ') for name in shap_data_df.columns]
        feature_mapping = {clean: orig for clean, orig in zip(feature_options, shap_data_df.columns)}
        
        # æ‰¾å‡ºæœ€é‡è¦çš„ç‰¹å¾ä½œä¸ºé»˜è®¤é€‰é¡¹
        vals = np.abs(shap_values).mean(0)
        feature_importance = pd.DataFrame(list(zip(feature_options, vals)), columns=['col_name','feature_importance_vals'])
        feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)
        most_important_feature = feature_importance.iloc[0].col_name
        default_index = feature_options.index(most_important_feature) if most_important_feature in feature_options else 0
        
        selected_feature_cleaned = st.selectbox("é€‰æ‹©å˜é‡", options=feature_options, index=default_index)
        
        # å°†ç”¨æˆ·é€‰æ‹©çš„æ¸…æ™°åç§°æ˜ å°„å›åŸå§‹åˆ—å
        selected_feature_orig = feature_mapping[selected_feature_cleaned]

        if selected_feature_orig in shap_value_df.columns:
            fig = px.scatter(
                x=shap_data_df[selected_feature_orig], 
                y=shap_value_df[selected_feature_orig], 
                color=shap_data_df[selected_feature_orig],
                color_continuous_scale=['blue','red'],
                labels={'x': f'{selected_feature_cleaned} çš„åŸå§‹å€¼', 'y': 'SHAPå€¼'}
            )
            fig.update_layout(coloraxis_showscale=False)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning(f"ç‰¹å¾ '{selected_feature_cleaned}' çš„SHAPå€¼ä¸å­˜åœ¨ã€‚")
        st.info('SHAPä¾èµ–å›¾æ˜¾ç¤ºäº†å•ä¸ªå˜é‡å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“ã€‚å®ƒè¯´æ˜äº†ä¸€ä¸ªç‰¹å¾çš„æ¯ä¸ªå€¼æ˜¯å¦‚ä½•å½±å“é¢„æµ‹ç»“æœçš„ã€‚')

def display_local_explanations(model, user_input_df, X_train):
    """æ˜¾ç¤ºå±€éƒ¨æ¨¡å‹è§£é‡Šï¼ˆSHAPåŠ›å›¾å’ŒLIMEå›¾ï¼‰"""
    st.subheader("å±€éƒ¨è§£é‡Š")
    
    # --- SHAP åŠ›å›¾ ---
    st.write('**SHAPåŠ›å›¾**')
    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(user_input_df)
        
        # åˆ›å»º SHAP åŠ›å›¾å¯¹è±¡
        plot = shap.force_plot(
            explainer.expected_value,
            shap_values[0, :],
            user_input_df.iloc[0, :]
        )
        
        # å°†å›¾ä¿å­˜åˆ°å†…å­˜ä¸­çš„HTMLæ–‡ä»¶ï¼Œç¡®ä¿JSè¢«åŒ…å«
        shap_html_path = io.StringIO()
        shap.save_html(shap_html_path, plot)
        
        # ä»å†…å­˜ä¸­è¯»å–HTMLå¹¶æ˜¾ç¤º
        components.html(shap_html_path.getvalue(), height=200)
        
        st.info('''
        **SHAPåŠ›å›¾è¯´æ˜:**
        - æ˜¾ç¤ºå„ç‰¹å¾å¦‚ä½•å°†é¢„æµ‹å€¼ä»åŸºç¡€å€¼æ¨è‡³æœ€ç»ˆé¢„æµ‹å€¼
        - çº¢è‰²ç‰¹å¾å¢åŠ ä½è¡€å‹é£é™©
        - è“è‰²ç‰¹å¾é™ä½ä½è¡€å‹é£é™©
        - ç®­å¤´é•¿åº¦è¡¨ç¤ºå½±å“å¤§å°
        ''')
    except Exception as e:
        st.error(f"ç”ŸæˆSHAPåŠ›å›¾æ—¶å‡ºé”™: {e}")

    # --- LIME è§£é‡Š ---
    st.write('**LIMEè§£é‡Š**')
    try:
        # ç¡®ä¿ X_train æ˜¯ numpy array
        if isinstance(X_train, pd.DataFrame):
            X_train_values = X_train.values
        else:
            X_train_values = X_train

        # å°†ç‰¹å¾åä¸­çš„ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œä»¥æé«˜å¯è¯»æ€§
        feature_names_cleaned = [name.replace('_', ' ') for name in X_train.columns]

        explainer = lime_tabular.LimeTabularExplainer(
            X_train_values, 
            feature_names=feature_names_cleaned, # ä½¿ç”¨æ¸…ç†åçš„ç‰¹å¾å
            class_names=['éä½è¡€å‹', 'ä½è¡€å‹'], 
            mode='classification',
            feature_selection='auto'
        )
        
        exp = explainer.explain_instance(
            user_input_df.values[0], 
            model.predict_proba, 
            num_features=10,
            labels=(1,) # åªè§£é‡Š"ä½è¡€å‹"ç±»åˆ«
        )
        
        # --- æ‰‹åŠ¨ç”ŸæˆLIMEå›¾ä»¥è‡ªå®šä¹‰é¢œè‰² ---
        # çº¢è‰²ä»£è¡¨å¢åŠ é£é™©ï¼Œç»¿è‰²ä»£è¡¨é™ä½é£é™©
        exp_list = exp.as_list(label=1)
        
        # æ£€æŸ¥æ˜¯å¦è·å¾—äº†æœ‰æ•ˆçš„è§£é‡Š
        if not exp_list:
            st.warning("LIME æœªèƒ½ä¸ºå½“å‰è¾“å…¥ç”Ÿæˆæœ‰æ•ˆçš„è§£é‡Šã€‚")
            return

        exp_list.reverse() # as_pyplot_figureä¼šåè½¬åˆ—è¡¨ï¼Œåœ¨æ­¤æ¨¡æ‹Ÿ
        
        vals = [x[1] for x in exp_list]
        names = [x[0] for x in exp_list]
        
        # äº¤æ¢é¢œè‰²ï¼šæ­£å‘å½±å“ï¼ˆå¢åŠ é£é™©ï¼‰ä¸ºçº¢è‰²ï¼Œè´Ÿå‘ä¸ºç»¿è‰²
        colors = ['#d62728' if x > 0 else '#2ca02c' for x in vals]
        
        pos = np.arange(len(exp_list))
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.barh(pos, vals, align='center', color=colors)
        
        ax.set_yticks(pos)
        ax.set_yticklabels(names)
        ax.set_title('Local explanation for class ä½è¡€å‹')
        fig.tight_layout()
        
        st.pyplot(fig)
        plt.close(fig)
        
        st.markdown('''
        **LIMEè§£é‡Šè¯´æ˜:**
        - æ˜¾ç¤ºå¯¹å½“å‰é¢„æµ‹å½±å“æœ€å¤§çš„ç‰¹å¾
        - **<font color='red'>çº¢è‰²æ¡ (å³ä¾§)</font>**: å¢åŠ ä½è¡€å‹é£é™©çš„ç‰¹å¾
        - **<font color='green'>ç»¿è‰²æ¡ (å·¦ä¾§)</font>**: é™ä½ä½è¡€å‹é£é™©çš„ç‰¹å¾
        - æ•°å€¼è¡¨ç¤ºå¯¹é¢„æµ‹çš„å…·ä½“å½±å“
        ''', unsafe_allow_html=True)
    except Exception as e:
        st.error(f"ç”ŸæˆLIMEå›¾æ—¶å‡ºé”™: {e}")

# --- ä¸»ç¨‹åº ---
def main():
    """Streamlitä¸»å‡½æ•°"""
    st.markdown("<h1 style='text-align: center; color: #1E90FF;'>ICUè‚¾è„æ›¿ä»£æ²»ç–—ä½è¡€å‹é£é™©é¢„æµ‹</h1>", unsafe_allow_html=True)
    
    # åŠ è½½èµ„æº
    shap_image = None
    try:
        model = load_model("hypotension_model.json")
        feature_names = load_feature_names("model_features.pkl")
        training_data = load_training_data("train.csv") # ç¡®ä¿train.csvåœ¨åŒçº§ç›®å½•
        X_train_processed = preprocess_data(training_data.copy(), feature_names)
        try:
            shap_image = load_images("shap.png")
        except FileNotFoundError:
            st.warning("`shap.png` æ–‡ä»¶æœªæ‰¾åˆ°ï¼ŒSHAPç‰¹å¾é‡è¦æ€§å›¾å°†æ— æ³•æ˜¾ç¤ºã€‚è¯·è¿è¡Œ `generate_shap_image.py` è„šæœ¬ç”Ÿæˆè¯¥æ–‡ä»¶ã€‚")

    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹æˆ–æ•°æ®æ—¶å‡ºé”™: {e}")
        st.error("è¯·ç¡®ä¿ `hypotension_model.json`, `model_features.pkl` å’Œ `train.csv` æ–‡ä»¶ä½äºåº”ç”¨æ ¹ç›®å½•ã€‚")
        return
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    st.info('''
    **å…³äºæ¨¡å‹:**
    - é¢„æµ‹ç›®æ ‡: ICUæ‚£è€…è¿›è¡Œè‚¾è„æ›¿ä»£æ²»ç–—æœŸé—´å‘ç”Ÿä½è¡€å‹çš„é£é™©
    - æ¨¡å‹ç±»å‹: XGBoost
    - ç‰¹å¾æ•°é‡: 17ä¸ªä¸´åºŠç›¸å…³æŒ‡æ ‡
    - ä½¿ç”¨è¯´æ˜: åœ¨å·¦ä¾§è¾“å…¥æ‚£è€…ç‰¹å¾åï¼Œç³»ç»Ÿå°†å®æ—¶è®¡ç®—ä½è¡€å‹å‘ç”Ÿæ¦‚ç‡
    ''')
    
    # ä¾§è¾¹æ è¾“å…¥
    with st.spinner("åŠ è½½è¾“å…¥è¡¨å•..."):
        user_input_df = sidebar_input_features(feature_names)
    
    # é¢„æµ‹
    st.subheader('ä½è¡€å‹é£é™©é¢„æµ‹')
    try:
        prediction_proba = model.predict_proba(user_input_df)[0][1]
        
        # ç»Ÿä¸€é£é™©ç­‰çº§å®šä¹‰
        if prediction_proba > 0.7:
            risk_level = "é«˜é£é™©"
        elif prediction_proba > 0.5:
            risk_level = "ä¸­é£é™©"
        else:
            risk_level = "ä½é£é™©"
        
        # åˆ›å»ºè¿›åº¦æ¡ (å°†numpy.float32è½¬æ¢ä¸ºfloat)
        st.progress(float(prediction_proba))
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="ä½è¡€å‹å‘ç”Ÿæ¦‚ç‡", value=f"{prediction_proba:.2%}")
        with col2:
            st.metric(label="é£é™©ç­‰çº§", value=risk_level)
            
        # é£é™©è§£é‡Š
        if prediction_proba > 0.7:
            st.warning("âš ï¸ é«˜é£é™©é¢„è­¦: è¯¥æ‚£è€…å‘ç”Ÿä½è¡€å‹çš„å¯èƒ½æ€§å¾ˆé«˜ï¼Œå»ºè®®é‡‡å–é¢„é˜²æªæ–½")
        elif prediction_proba > 0.5:
            st.warning("âš ï¸ ä¸­é£é™©é¢„è­¦: è¯¥æ‚£è€…æœ‰ä¸€å®šä½è¡€å‹é£é™©ï¼Œå»ºè®®å¯†åˆ‡ç›‘æµ‹")
        else:
            st.success("âœ… ä½é£é™©: è¯¥æ‚£è€…ä½è¡€å‹é£é™©è¾ƒä½")
            
    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {e}")
    
    # ç‰¹å¾é‡è¦æ€§è§£é‡Š
    st.subheader("ç‰¹å¾é‡è¦æ€§è§£é‡Š")
    display_global_explanations(model, X_train_processed, shap_image)
    
    # å±€éƒ¨è§£é‡Š
    st.subheader("å½“å‰é¢„æµ‹è§£é‡Š")
    display_local_explanations(model, user_input_df, X_train_processed)

if __name__ == "__main__":
    main()